---
title: "Modelling Zollikofen"
output:
  html_document:
    toc: yes
    toc_float: yes
    number_sections: yes
  pdf_document:
    toc: yes
editor_options:
  markdown:
    wrap: 75
---

Course: Field Course Micrometeorology and Urban Climate at the University
of Bern (Institute of Geography)

Supervisor: Prof. Dr. Stefan Brönnimann

Adviser: Dr. Moritz Gubler

[Do you have questions about the workflow? Contact the
Authors:]{.underline}

Bigler Patrick
([patrick.bigler1\@students.unibe.ch](mailto:patrick.bigler1@students.unibe.ch){.email})

Sarah Ogi (sarah.ogi\@students.unibe.ch)

Markella Bouchoriku (markella.bouchoriku\@students.unibe.ch )

Reference: "Spatial Upscaling"

# Introduction

|              |                   |
|--------------|-------------------|
| Coordinates: | 7°28' E, 46°59' N |
| Altitude:    | 552 a.s.l.        |
| Time:        | UTC / GMT         |
| Source:      | Meteo Schweiz     |

: Table 1: Metadata for the MeteoSchweiz station in Zollikofen (reference
station)

+----------------+----------------------------------------+
| Altitude:      | 7° 27' 50,65'' E ; 46.° 59' 26,844'' N |
+----------------+----------------------------------------+
| Altitude:      | 552.9 a.s.l.                           |
+----------------+----------------------------------------+
| Time format:   | Old logger: UTC-2 / GMT-2              |
|                |                                        |
|                | New Logger: UTC / GMT                  |
+----------------+----------------------------------------+
| Logger Number: | 98                                     |
+----------------+----------------------------------------+
| Code grafana   | 20d1b9040ad9                           |
+----------------+----------------------------------------+

: Table 2: Metadata for the 2m Logger in Zollikofen

+----------------+----------------------------------------+
| Altitude:      | 7° 27' 50,65'' E ; 46.° 59' 26,844'' N |
+----------------+----------------------------------------+
| Altitude:      | 552.9 a.s.l.                           |
+----------------+----------------------------------------+
| Time format:   | Old logger: UTC-2 / GMT-2              |
|                |                                        |
|                | New Logger: UTC / GMT                  |
+----------------+----------------------------------------+
| Logger Number: | 99                                     |
+----------------+----------------------------------------+
| Code grafana   | 135a449d34a1                           |
+----------------+----------------------------------------+

: Table 3: Metadata for the 3m Logger in Zollikofen

# Preparation

## Read packages

First, we install and / or load packages we need. Important is the package
"conflicted". It enables us to chose if different functions have the same
call but do not make the same thing (a function in a certain package can
have the same name as a function from another package).

```{r read_the_packages, warning=FALSE, error=FALSE, message=FALSE}
# install and activate all packages we need
source("../Field_Course_Urban_Climate/R/general/packages.R")

# We set preferences
conflicts_prefer(ggplot2::annotate)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::mutate)
conflicts_prefer(dplyr::filter)
conflicts_prefer(dplyr::rename)
conflicts_prefer(Metrics::rmse)
conflicts_prefer(Metrics::mae)
conflicts_prefer(lubridate::stamp)
conflicts_prefer(lubridate::hour)
conflicts_prefer(recipes::fixed)
```

## Read data

We read all the data we need:

```{r read_the_data, warning=FALSE, error=FALSE, message=FALSE}
# We read the reference data from Zollikofen
ZOLL <- read.csv2("../Field_Course_Urban_Climate/data/data_REF_ZOLL.original.csv")

```

## Time and date

We define CEST as our time and use "lubridate" to define a date.

```{r time_and_date, warning=FALSE, error=FALSE, message=FALSE}

# We change format of time and date for reference station in Zollikofen
ZOLL$time <- strptime(ZOLL$time, format="%Y%m%d%H%M")
ZOLL$time <- as.POSIXct(ZOLL$time, tz = "ETC/GMT")
attr(ZOLL$time, "tzone")

ZOLL <- ZOLL|>
  mutate('windspeed' = as.numeric(as.character(unlist(ZOLL[,'fu3010z0']))),
         'winddirection' = as.numeric(as.character(unlist(ZOLL[,'dkl010z0']))),
         'precipitation' = as.numeric(as.character(unlist(ZOLL[,'rre150z0']))),
         'humidity' = as.numeric(as.character(unlist(ZOLL[,'ure200s0']))),
         'insolation' = as.numeric(as.character(unlist(ZOLL[,'gre000z0']))),
         'temperature' = as.numeric(as.character(unlist(ZOLL[,'tre200s0']))))|>
  select(c('time', 'temperature', 'humidity', 'insolation', 'windspeed', 'winddirection'))
```

# Stepwise regression

we create a stepwise regression because we want to know which model is
properly the best fit. The model with the lowest AIC will be preferred.

```{r}
source('../Field_Course_Urban_Climate/R/stepwise/stepforward.R')

multivariate.reg.model(ZOLL, c(1, 2, 3))
```

# Implementation of KNN

## Split data and model training

-   Split data

-   Training

-   optimaze k (overfit vs. underfit)

### Zollikofen: expanded-model

First, we calculate a model with all our meteorological variable (humidity,
insolation, wind speed, wind direction). We call it our KNN-expanded model.

```{r split_the_data, warning=FALSE, error=FALSE, message=FALSE }
# We load our functions
source("../Field_Course_Urban_Climate/R/ml_functions.approach/knn.evaluation.approach.R")
source("../Field_Course_Urban_Climate/R/ml_functions.approach/lm.and.knn.model.approach.R")
source("../Field_Course_Urban_Climate/R/ml_functions.approach/knn_cv_optimizer.approach.R")
source("../Field_Course_Urban_Climate/R/ml_functions.approach/knn.cv.model.creater.approach.R")

# For reproducibility (pseudo random choice)
set.seed(123)  

# Split 70 % to 30 % 
split_zoll_approach <- rsample::initial_split(ZOLL, prop = 0.7)
# We create a training set and a test set
ZOLL_train_approach <- rsample::training(split_zoll_approach)
ZOLL_test_approach <- rsample::testing(split_zoll_approach)


# We optimaze the hyperparameter k --> k = 2
parameter.extracter.knn.cv.a(c(1:10), ZOLL_train_approach, ZOLL_test_approach , 10)


# We calculate a KNN model
model.ZOLL.opt.appraoch <- knn.cv.model.a(ZOLL_train_approach, 2)

# We calculate a lm-model (to comapre with)
model.ZOLL.lm.approach <- lm.model.a(ZOLL_train_approach)
```

### Zollikofen: Simple-model

We calculate a model with the target 'temperature' and humidity as
predictor.

```{r}
# We load our functions
source("../Field_Course_Urban_Climate/R/ml_functions/knn.evaluation.R")
source("../Field_Course_Urban_Climate/R/ml_functions/lm.and.knn.model.R")
source("../Field_Course_Urban_Climate/R/ml_functions/knn_cv_optimizer.R")
source("../Field_Course_Urban_Climate/R/ml_functions/knn.cv.model.creater.R")

# For reproducibility (pseudo random choice)
set.seed(123)  

# Split 70 % to 30 % 
split_zoll <- rsample::initial_split(ZOLL, prop = 0.7)
# We create a training set and a test set
ZOLL_train <- rsample::training(split_zoll)
ZOLL_test <- rsample::testing(split_zoll)

# We optimaze the hyperparameter k --> k=170
my.sequence <-c(1,2,3,4,5, seq(100, to = 200, by = 10))
parameter.extracter.knn.cv(my.sequence, ZOLL_train, ZOLL_test , 10)

# We calculate a KNN model
model.ZOLL.opt <- knn.cv.model(ZOLL_train, 170)

# We calculate a lm-model (to comapre with)
model.ZOLL.lm <- lm.model(ZOLL_train)
```

# Evaluation

## Performance Zollikofen

Here, we evaluate Zollikofen. We use our simple model (model.ZOLL.opt)
which contains only the target (temperature) and a predictor (humidity). We
compare our knn-model with the lm-model. We easily see that the knn
performce better than lm-model (RSQ: 0.77 vs. 0.74, RMSE: 2.54 vs. 2.7).

If we use our expanded model (model.ZOLL.opt.appraoch), which contains the
target (temperature) and the predictors (humidity, insolation, windspeed
and winddirection), the performance increase massively (RSQ: 0.86 vs. 0.78,
RMSE: 1.95 vs. 2.46). We see that especially the error is thereby lowered
massively and the RSQ increase.

Now, we know the expanded KNN model is superior to all other models. Thus,
it would be preferable to use this one. Unfortunately, the new loggers
measure only temperature and humidity. We must therefore work with the
simple model. However, we recommend to extend the measurements in order to
be able to use the extended model later.

```{r evaluation-of-zollikofen, warning=FALSE, error=FALSE, message=FALSE}
# simple KNN
eval_model(model.ZOLL.opt, ZOLL_train, ZOLL_test, 
           c("Zoll: KNN (k = 170)"), c("Zoll: KNN (k = 170)"))

# simple lm
eval_model(model.ZOLL.lm, ZOLL_train, ZOLL_test, 
           c("Zoll: lm-model"), c("Zoll: lm-model"))

# expanded KNN
eval_model(model.ZOLL.opt.appraoch, ZOLL_train_approach, ZOLL_test_approach, 
           c("Zoll: KNN-expanded (k = 2)"), c("Zoll: KNN-expanded (k = 2)"))

# expanded lm
eval_model(model.ZOLL.lm.approach, ZOLL_train_approach, ZOLL_test_approach, 
           c("Zoll: lm-model-expanded"), c("Zoll: lm-model-expanded"))
```

## Zollikofen 2m Logger

We evaluate the 2m logger in Zollikofen

```{r read-new-logger-2m, warning=FALSE, error=FALSE, message=FALSE}

# We read data from the new logger in Zollikofen (2m)
new_logger_zoll_2 <- read.csv("../Field_Course_Urban_Climate/data/data_logger_new/20d1b9040ad9.csv") 

# We change format of time and date for the new logger in Zollikofen (2m)
new_logger_zoll_2$time <- gsub('[TZ]',' ', new_logger_zoll_2$time)
new_logger_zoll_2$time <- strptime(new_logger_zoll_2$time, format="%Y-%m-%d %H:%M")
new_logger_zoll_2$time <- as.POSIXct(new_logger_zoll_2$time, tz = "Etc/GMT")
attr(new_logger_zoll_2$time, "tzone")

new_logger_zoll_2 <- new_logger_zoll_2|>
  mutate('time' = lubridate::round_date(time,"10 minutes"))|>
  rename('temperature' = decodedXpayload_temperature,
         'humidity' = decodedXpayload_humidity)

# expanded KNN
eval_model(model.ZOLL.opt, ZOLL_train, new_logger_zoll_2, 
           c("Zoll: KNN (k = 2)"), c("Zoll: KNN (k = 2)"))

# expanded lm
eval_model(model.ZOLL.lm, ZOLL_train, new_logger_zoll_2, 
           c("Zoll: lm-model"), c("Zoll: lm-model"))
```

## Zollikofen 3m Logger

And we evaluate the 3m logger in Zollikofen

```{r read-new-logger-3m, warning=FALSE, error=FALSE, message=FALSE}
# We read data from the new logger in Zollikofen (3m)
new_logger_zoll_3 <- read.csv("../Field_Course_Urban_Climate/data/data_logger_new/135a449d34a1.csv")

# We change format of time and date for the new logger in Zollikofen (2m)
new_logger_zoll_3$time <- gsub('[TZ]',' ', new_logger_zoll_3$time)
new_logger_zoll_3$time <- strptime(new_logger_zoll_3$time, format="%Y-%m-%d %H:%M")
new_logger_zoll_3$time <- as.POSIXct(new_logger_zoll_3$time, tz = "Etc/GMT")
attr(new_logger_zoll_3$time, "tzone")

new_logger_zoll_3 <- new_logger_zoll_3|>
  mutate('time' = lubridate::round_date(time,"10 minutes"))|>
  rename('temperature' = decodedXpayload_temperature,
         'humidity' = decodedXpayload_humidity)

# expanded KNN
eval_model(model.ZOLL.opt, ZOLL_train, new_logger_zoll_3, 
           c("Zoll: KNN-expanded (k = 2)"), c("Zoll: KNN-expanded (k = 2)"))

# expanded lm
eval_model(model.ZOLL.lm, ZOLL_train, new_logger_zoll_3, 
           c("Zoll: lm-model-expanded"), c("Zoll: lm-model-expanded"))
```

# Spatial up-scaling

## Read multiple csv-files at once

We read multiple csv-files at once

We exclude LCD 102 (Vordere Länggasse) and LCD 13 (Egelsee) because there
are not such files in the folder. We also exclude LCD 52 (Umland Bümpliz)
because the LCD is not in use. That means we analyse only 20/23
locations...

```{r read-multiple-csv-files, warning=FALSE, error=FALSE, message=FALSE}
# we read all the file names
list_of_files <- list.files(path = '../Field_Course_Urban_Climate/data/data_logger_new/',
                            recursive = TRUE,
                            pattern = '\\.csv$',
                            full.names = TRUE)

# We save them in a data frame
df_new_loggers <- readr::read_csv(list_of_files, id = "file_name")

# We need only double measurements --> create a filter
df_metadata <- read_xlsx("../Field_Course_Urban_Climate/data/metadata_network_2023.xlsx")

df_metadata <- df_metadata|>
  # We want only double measurements, we need the code as well
  filter(Doppel_Messnetz_23 == 'ja' & `Code grafana` != 'nocht nicht installiert')|>
  select(Log_NR, `Code grafana`, NORD_CHTOPO, OST_CHTOPO,HüM)

# we extract the identification code of the loggers
logger_code <- df_metadata$`Code grafana`

# because there are errors by reading the files, we use only the first four characters
logger_code <- str_sub(logger_code , end = -9)

# We create our own filter (with logical "or")
own.filter <- logger_code|>
  paste(collapse = "|")

# and we have a data frame which contains only locations with a double measurement
# Now we can use group_by or a filter to analize all locations at once
df_new_loggers <- df_new_loggers |>
  filter(str_detect(name, own.filter))|>
  rename('temperature' = decodedXpayload_temperature,
         'humidity' =decodedXpayload_humidity)|>
  select(c('time', 'name', 'temperature', 'humidity'))
```

### Control-Plot

It is only a control plot. Now we know that we work with 20 LCDs...

```{r control_plot, warning=FALSE, error=FALSE, message=FALSE}
# We create a control-plot to check wheter we have 22 locations
df_new_loggers|>
  group_by(name)|>
    ggplot(aes(x = time, y = temperature, color = name ))+
  geom_line()+
  theme_light()
```

# Modelling

## KNN-models and lm-models for all 20 locations at once

```{r}
# We change format of time and date for reference station in Zollikofen
df_new_loggers$time <- strptime(df_new_loggers$time , format = "%Y-%m-%d %H:%M")
df_new_loggers$time <- as.POSIXct(df_new_loggers$time, tz = "ETC/GMT-2")
attr(df_new_loggers$time, "tzone")

df_new_loggers <- df_new_loggers|>
  mutate(time = lubridate::round_date(time,"10 minutes"))

# filter to control for-loop
filter <- dplyr::pull(df_new_loggers|>
                        group_by(name)|>
                        group_keys(name))



dataset = NULL
source("../Field_Course_Urban_Climate/R/ml_functions/spatial.upscale.R")
source("../Field_Course_Urban_Climate/R/ml_functions/metric_extracter.R")

# define vectors
rmse_test_knn <- NULL
rsq_test_knn <- NULL
bias_test_knn <- NULL
rmse_test_lm <- NULL
rsq_test_lm <- NULL
bias_test_lm <- NULL
# for loop to extract metrics
for (i in filter){
  # filter after logger code
  df_temporary <- subset(df_new_loggers, name == i)
  # create a temporare data frame
  rmse_test_knn <- c(rmse_test_knn, rmse_extracter(model.ZOLL.opt, ZOLL_train, df_temporary))
  rsq_test_knn <- c(rsq_test_knn, rsq_extracter(model.ZOLL.opt, ZOLL_train, df_temporary))
  bias_test_knn <- c(bias_test_knn, bias_extracter(model.ZOLL.opt, ZOLL_train, df_temporary))
  rmse_test_lm <- c(rmse_test_lm, rmse_extracter(model.ZOLL.lm, ZOLL_train, df_temporary))
  rsq_test_lm <- c(rsq_test_lm, rsq_extracter(model.ZOLL.lm, ZOLL_train, df_temporary))
  bias_test_lm <- c(bias_test_lm, bias_extracter(model.ZOLL.lm, ZOLL_train, df_temporary))
}

overview <- data.frame('Logger-code' = filter,
                       'RSME KNN' = rmse_test_knn,
                       'RSQ KNN' = rsq_test_knn ,
                       'Bias KNN' = bias_test_knn,
                       'RSME lm' = rmse_test_lm,
                       'RSQ lm' = rsq_test_lm,
                       'Bias lm' = bias_test_lm)
# generate latex code
xtable(overview, align = c('l','l', 'c', 'c', 'c', 'c', 'c', 'c'))
```

## Evaluation of spatial upscale

```{r}
# We change format of time and date for reference station in Zollikofen
df_new_loggers$time <- strptime(df_new_loggers$time , format = "%Y-%m-%d %H:%M")
df_new_loggers$time <- as.POSIXct(df_new_loggers$time, tz = "ETC/GMT-2")
attr(df_new_loggers$time, "tzone")

df_new_loggers <- df_new_loggers|>
  mutate(time = lubridate::round_date(time,"10 minutes"))

# filter to control for-loop
filter <- dplyr::pull(df_new_loggers|>
  group_keys(name), name)

dataset = NULL
source("../Field_Course_Urban_Climate/R/ml_functions/spatial.upscale.R")
# create a for loop --> it will create 40 plots!!
for (i in filter){
  dataset <- c(dataset, i)
  # filter after logger code
  df_temporary <- subset(df_new_loggers, name == i)
  # create a temporare data frame
  knn <- eval_model.upscale(model.ZOLL.opt, ZOLL_train, df_temporary, 
           c("Zoll: KNN (k = 2)"), c("Zoll: KNN (k = 2)"), i)
  lm <- eval_model.upscale(model.ZOLL.lm, ZOLL_train, df_temporary, 
           c("Zoll: lm-model"), c("Zoll: lm-model"), i)
  print(knn)
  print(lm)
}
```
