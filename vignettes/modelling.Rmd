---
title: "Modelling AFU"
output:
  html_document:
    toc: yes
    toc_float: yes
    number_sections: yes
  pdf_document:
    toc: yes
editor_options:
  markdown:
    wrap: 75
---

Course: Field Course Micrometeorology and Urban Climate at the University
of Bern (Institute of Geography)

Supervisor: Prof. Dr. Stefan Brönnimann

Adviser: Dr. Moritz Gubler

Do you have questions about the workflow? Contact the Authors:

Bigler Patrick
([patrick.bigler1\@students.unibe.ch](mailto:patrick.bigler1@students.unibe.ch){.email})

Sarah Ogi
([sarah.ogi\@students.unibe.ch](mailto:sarah.ogi@students.unibe.ch){.email})

Markella Bouchoriku
([markella.bouchoriku\@students.unibe.ch](mailto:markella.bouchoriku@students.unibe.ch){.email}
)

Reference: "modelling"

# Introduction

|              |                   |
|--------------|-------------------|
| Coordinates: | 7°28' E, 46°59' N |
| Altitude:    | 552 a.s.l.        |
| Time:        | UTC / GMT         |
| Source:      | Meteo Schweiz     |

: Table 1: Metadata for the MeteoSchweiz station in Zollikofen (reference
station)

|              |                                         |
|--------------|-----------------------------------------|
| Coordinates: | 7° 27' 45,252'' E ; 46.° 57' 47,196'' N |
| Altitude:    | 554.5 a.s.l.                            |
| Time:        | UTC-2 / GMT-2                           |
| Source:      | AFU (Amt für Umwelt der Stadt Bern)     |

: Table 2: Metadata for AFU (reference station)

+-----------------+-----------------------------------------+
| Altitude:       | 7° 27' 50,65'' E ; 46.° 59' 26,844'' N  |
+-----------------+-----------------------------------------+
| Altitude:       | 552.9 a.s.l.                            |
+-----------------+-----------------------------------------+
| Time format:    | Old logger: UTC-2 / GMT-2               |
|                 |                                         |
|                 | New Logger: UTC / GMT                   |
+-----------------+-----------------------------------------+
| Logger Number:  | 98                                      |
+-----------------+-----------------------------------------+
| Code grafana    | 20d1b9040ad9                            |
+-----------------+-----------------------------------------+

: Table 3: Metadata for the 2m Logger in Zollikofen

+-----------------+-----------------------------------------+
| Altitude:       | 7° 27' 50,65'' E ; 46.° 59' 26,844'' N  |
+-----------------+-----------------------------------------+
| Altitude:       | 552.9 a.s.l.                            |
+-----------------+-----------------------------------------+
| Time format:    | Old logger: UTC-2 / GMT-2               |
|                 |                                         |
|                 | New Logger: UTC / GMT                   |
+-----------------+-----------------------------------------+
| Logger Number:  | 99                                      |
+-----------------+-----------------------------------------+
| Code grafana    | 135a449d34a1                            |
+-----------------+-----------------------------------------+

: Table 4: Metadata for the 3m Logger in Zollikofen

+-----------------+------------------------------------------+
| Altitude:       | 7° 27' 45,252'' E ; 46.° 57' 47,196'' N  |
+-----------------+------------------------------------------+
| Altitude:       | 554.5 a.s.l.                             |
+-----------------+------------------------------------------+
| Time format:    | Old logger: UTC-2 / GMT-2                |
|                 |                                          |
|                 | New Logger: UTC / GMT                    |
+-----------------+------------------------------------------+
| Logger Number:  | 83                                       |
+-----------------+------------------------------------------+
| Code grafana    | d6e2769def35                             |
+-----------------+------------------------------------------+

: Table 5: Metadata for the 2m Logger at AFU

# Preparation

```{r read_the_packages, warning=FALSE, error=FALSE, message=FALSE}
# install and activate all packages we need
source("../R/general/packages.R")

# We set preferences
conflicts_prefer(ggplot2::annotate)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::mutate)
conflicts_prefer(dplyr::filter)
conflicts_prefer(dplyr::rename)
```

```{r read_the_data, warning=FALSE, error=FALSE, message=FALSE}
# We read the reference data from Zollikofen
ZOLL <- read.csv2("../data/data_REF_ZOLL.original.csv")

# We read the reference data from AFU
AFU <- read_xlsx("../data/data_REF_AFU_new.xlsx")
```

```{r file-preparation, error=FALSE, warning=FALSE, message=FALSE}
# We change format of time and date for reference station in Zollikofen
ZOLL$time <- strptime(ZOLL$time, format="%Y%m%d%H%M")
ZOLL$time <- as.POSIXct(ZOLL$time, tz = "ETC/GMT")
attr(ZOLL$time, "tzone")

ZOLL <- ZOLL|>
  mutate('windspeed' = as.numeric(as.character(unlist(ZOLL[,'fu3010z0']))),
         'winddirection' = as.numeric(as.character(unlist(ZOLL[,'dkl010z0']))),
         'precipitation' = as.numeric(as.character(unlist(ZOLL[,'rre150z0']))),
         'humidity' = as.numeric(as.character(unlist(ZOLL[,'ure200s0']))),
         'insolation' = as.numeric(as.character(unlist(ZOLL[,'gre000z0']))),
         'temperature' = as.numeric(as.character(unlist(ZOLL[,'tre200s0']))))|>
  select(c('time', 'temperature', 'humidity', 'insolation', 'windspeed', 'winddirection'))

# We change format of time and date for reference station in front of AFU
AFU$Zeit <- format(AFU$Zeit, format = "%H:%M")
AFU$Datum <- strptime(paste(AFU$Datum,AFU$Zeit,sep = " "), format="%Y-%m-%d %H:%M") 
AFU$Datum <- as.POSIXct(AFU$Datum, tz = "Etc/GMT-2")
attr(AFU$Datum, "tzone")

AFU <- AFU|>
  rename('time' =  Datum,
         'temperature' = Temp,
         'windspeed' = WG,
         'winddirection' = WR...5,
         'insolation' = GS,
         'pressure' = Luftdruck,
         'humidity' = Feuchte)|>
  select(c('time', 'temperature', 'humidity', 'insolation', 'windspeed', 'winddirection'))
```

# Maschine Learning (KNN-Algorithm)

## General Zollikofen

```{r calculate-AFU-models, warning=FALSE, error=FALSE, message=FALSE}
# We load our functions
source("../R/ml_functions.approach/knn.evaluation.approach.R")
source("../R/ml_functions.approach/lm.and.knn.model.approach.R")
source("../R/ml_functions.approach/knn_cv_optimizer.approach.R")
source("../R/ml_functions.approach/knn.cv.model.creater.approach.R")

# For reproducibility (pseudo random choice)
set.seed(123)  

# Split 70 % to 30 % 
split_zoll_approach <- rsample::initial_split(ZOLL, prop = 0.7)
# We create a training set and a test set
ZOLL_train_approach <- rsample::training(split_zoll_approach)
ZOLL_test_approach <- rsample::testing(split_zoll_approach)

# We optimaze the hyperparameter k --> k=170
my.sequence <-c(1,2,3,4,5, seq(100, to = 200, by = 10))
parameter.extracter.knn.cv.a(my.sequence, ZOLL_train_approach, ZOLL_test_approach , 10)


# We calculate a KNN model
model.ZOLL.opt.appraoch <- knn.cv.model.a(ZOLL_train_approach, 2)

# We calculate a lm-model (to comapre with)
model.ZOLL.lm.approach <- lm.model.a(ZOLL_train_approach)
```

## General AFU

```{r calculate-AFU-model, warning=FALSE, error=FALSE, message=FALSE}
# For reproducibility
set.seed(123)  

# Split 70 % to 30 % 
split_AFU_approach <- rsample::initial_split(AFU, prop = 0.7)
# We create a training set and a test set
AFU_train_approach <- rsample::training(split_AFU_approach)
AFU_test_approach <- rsample::testing(split_AFU_approach)

# We optimaze the hyperparameter k --> k=170
my.sequence <-c(1,2,3,4,5, seq(10, to = 50, by = 5))
parameter.extracter.knn.cv.a(my.sequence, AFU_train_approach, AFU_test_approach , 10)


# We calculate a KNN model
model.AFU.opt.approach <- knn.cv.model.a(AFU_train_approach, 5)

# We calculate a lm-model (to comapre with)
model.AFU.lm.approach <- lm.model.a(AFU_train_approach)
```

## Zollikofen

```{r knn-model-zollikofen, warning=FALSE, error=FALSE, message=FALSE}
# We load our functions
source("../R/ml_functions/knn.evaluation.R")
source("../R/ml_functions/lm.and.knn.model.R")
source("../R/ml_functions/knn_cv_optimizer.R")
source("../R/ml_functions/knn.cv.model.creater.R")

# For reproducibility (pseudo random choice)
set.seed(123)  

# Split 70 % to 30 % 
split_zoll <- rsample::initial_split(ZOLL, prop = 0.7)
# We create a training set and a test set
ZOLL_train <- rsample::training(split_zoll)
ZOLL_test <- rsample::testing(split_zoll)

# We optimaze the hyperparameter k --> k=170
my.sequence <-c(1,2,3,4,5, seq(100, to = 200, by = 10))
parameter.extracter.knn.cv(my.sequence, ZOLL_train, ZOLL_test , 10)

# We calculate a KNN model
model.ZOLL.opt <- knn.cv.model(ZOLL_train, 170)

# We calculate a lm-model (to comapre with)
model.ZOLL.lm <- lm.model(ZOLL_train)
```

## AFU

We do it the same for AFU...

```{r warning=FALSE, error=FALSE, message=FALSE }
# For reproducibility (pseudo-random)
set.seed(123)  
# Split 70 % to 30 % 
split_AFU <- rsample::initial_split(AFU, prop = 0.7)
# We create a training set and a test set
AFU_train <- rsample::training(split_AFU)
AFU_test <- rsample::testing(split_AFU)

# We optimaze the hyperparameter k --> k = 17
parameter.extracter.knn.cv(c(1:25), AFU_train, AFU_test , 10)

# We calculate a KNN model
model.AFU.opt <- knn.cv.model(AFU_train, 17)

# We calculate a lm-model (to comapre with)
model.AFU.lm <- lm.model(AFU_train)
```

# Evaluation, spatial up-scaling and estimate performance

## Evaluation of AFU

First, we evaluate AFU. We use our simple model (model.AFU.opt) which
contains only the target (temperature) and a predictor (humidity). We
compare our knn-model with the lm-model. We easily see that the knn
performce better than lm-model (RSQ: 0.72 vs. 0.67, RMSE: 2.71 vs. 2.95).

If we use our expanded model (model.AFU.opt.appraoch), which contains the
target (temperature) and the predictors (humidity, insolation, windspeed
and winddirection), the performance increase massively (RSQ: 0.83 vs. 0.71,
RMSE: 2.01 vs. 2.74). We see that especially the error is thereby lowered.

Now, we know the expanded KNN model is superior to all other models. Thus,
it would be preferable to use this one. Unfortunately, the new loggers
measure only temperature and humidity. We must therefore work with the
simple model. However, we recommend to extend the measurements in order to
be able to use the extended model later.

```{r model-evaluation-AFU,warning=FALSE, error=FALSE, message=FALSE }
# simple KNN
eval_model(model.AFU.opt, AFU_train_approach, AFU_test_approach, 
           c("AFU: KNN (k = 17)"), c("AFU: KNN (k = 17)"))

# simple lm
eval_model(model.AFU.lm, AFU_train_approach, AFU_test_approach, 
           c("AFU: lm-model"), c("AFU: lm-model"))

# expanded KNN
eval_model(model.AFU.opt.approach, AFU_train_approach, AFU_test_approach, 
           c("AFU: KNN-expanded (k = 17)"), 
           c("AFU: KNN-expanded (k = 17)"))

# expanden lm
eval_model(model.AFU.lm.approach, AFU_train_approach, AFU_test_approach, 
           c("AFU: lm-model-expanded"), c("AFU: lm-model-expanded"))
```

### Spatial up-scaling with AFU

Now, we try to predict Zollikofen with our AFU model. We see that our
simple knn-model is superior RSQ but not for Bias (0.72 vs. 0.67 , -0.08
vs. -0.02).

If we predict Zollikofen with our expanded models we clearly see, that is
would be the better approach than the simple one. KNN is also superior for
RSQ but not for Bias (0.83 vs. 0.71 , -0.09 vs. 0.01).

```{r upscaling-AFU, warning=FALSE, error=FALSE, message=FALSE}
# expanded KNN
eval_model(model.AFU.opt.approach, AFU_train_approach, ZOLL, 
           c("Zoll: KNN-expanded (k = 17)"), 
           c("Zoll: KNN-expanded (k = 17)"))

# expanden lm
eval_model(model.AFU.lm.approach, AFU_train_approach, ZOLL, 
           c("AFU: lm-model-expanded"), c("AFU: lm-model-expanded"))
```

### Logger prediction

Now we try to predict the logger at AFU with our AFU-models. For that, we
read logger data first and make some mutation with date and time.

```{r read-new-logger}
# We read data from the new logger in front of AFU (2m)
new_logger_AFU <- read.csv("../data/data_logger_new/d6e2769def35.csv")

# We change format of time and date for the new logger in front of AFU
new_logger_AFU$time <- gsub('[TZ]',' ', new_logger_AFU$time)
new_logger_AFU$time <- strptime(new_logger_AFU$time, format = "%Y-%m-%d %H:%M")
new_logger_AFU$time <- as.POSIXct(new_logger_AFU$time, tz = "Etc/GMT")
attr(new_logger_AFU$time, "tzone")
# We round the time to the next 10 minute and rename a column
new_logger_AFU <- new_logger_AFU|>
  mutate('time' = lubridate::round_date(time,"10 minutes"))|>
  rename('temperature' = decodedXpayload_temperature,
         'humidity' = decodedXpayload_humidity)

eval_model(model.AFU.opt, AFU_train_approach, new_logger_AFU, 
           c("AFU: KNN (k = 17)"), c("AFU: KNN (k = 17)"))

eval_model(model.AFU.lm, AFU_train_approach, new_logger_AFU, 
           c("AFU: lm-model"), c("AFU: lm-model"))
```

Expand on all double measurements locations

```{r}
#
list_of_files <- list.files("../data/data_logger_new/")|>
  as.data.frame('Name' = list_of_files)
list_of_files

#
df_old_loggers <- read_xlsx("../data/data_logger_old.xlsx")

df_metadata <- read_xlsx("../data/metadata_network_2023.xlsx")

df_metadata <- df_metadata|>
  filter(Doppel_Messnetz_23 == 'ja' & `Code grafana` != 'nocht nicht installiert')|>
  select(Log_NR, `Code grafana`, NORD_CHTOPO, OST_CHTOPO,HüM)


data_files <- list.files("../data/data_logger_new/")

for(i in 1:length(data_files)) {                             
  assign(paste0("data", i),                                   
         read.csv2(paste0("../data/data_logger_new/", data_files[i])))
}

dynamic_file_reader <- function(database = df_metadata){
  codes <- c(database|>
    select(`Code grafana`))
  file.names = NULL
  for (i in testi) {
    file.names <- c(file.names, paste0('../data/data_logger_new/',i, '.csv'))

    return(file.names)
    }
}

h <- dynamic_file_reader()
h

r <- read_csv("../data/data_logger_new/02f54d63d5c4.csv")
     char <- as.character(i)
    file <- paste0('file', '_char') <- read_csv(paste0('../data/data_logger_new/', 'file.names'))
converter <- function(database = df_old_loggers){
  
  new_number <- NULL
  log_vec <- NULL
  code
  nbr_logger <- df_old_loggers|>
  select(-c('Sommerzeit', 'Log_32', 'Log_39'))|>
  colnames()
for (i in nbr_logger) {
  new_character <- gsub("Log_", "", i)
  new_number <- as.numeric(new_character)
  log_vec <- c(log_vec, new_number)
}
  df_metadata|>
    filter()
  return(log_vec)
}

file_reader <- function(){
  
}
x <- converter()

x

which(df_metadata$Log_NR == x)

y <- df_metadata[x, ]


  select('Log_NR', 'Code grafana') |>
    filter(Log_NR == x)


```

as
